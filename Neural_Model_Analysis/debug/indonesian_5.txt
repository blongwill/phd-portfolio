Initializing debugger output file...
###
Experiment config settings:
config_name: indonesian_5
random_seed: 121
dataset: indonesian_processed_nostoppunct
model_type: bert-base-multilingual-uncased
optimizer: AdamW
learning_rate: 2e-5
epsilon: 1e-8
num_training_epochs: 2
num_warmup_steps: 0
num_classifier_labels: 3
output_attentions: True
output_hidden_states: True
batch_size: 16
max_tokens_length: 77
###
DATASETS: ['/home2/coman8/ling575_neural_models/src/../datasets/indonesian_processed_nostoppunct.txt']
Starting experiment execution
There are 1 GPU(s) available.
We will use the GPU:Tesla M10
Starting load dataset
First data label: 1
Finished load dataset
Loading BERT tokenizer...
Starting split dataset
Input IDs dimension-1 size: 9841
Input IDs dimension-2 size: 77
Input Labels dimension-1 size: 9841
Input Masks dimension-1 size: 9841
Input Masks dimension-2 size: 77
Train inputs dimension-1 size: 8856
Train inputs dimension-2 size: 77
Train labels dimension-1 size: 8856
Train masks dimension-1 size: 8856
Train masks dimension-2 size: 77
Finished split dataset
Made it here
Starting to Load BertForSequenceClassification
Finished initializing model
Starting train hate speech model

======== Epoch 1 / 2 ========
Training...
  Batch    40  of    554.    Elapsed: 0:00:38.
  Batch    80  of    554.    Elapsed: 0:01:16.
  Batch   120  of    554.    Elapsed: 0:01:54.
  Batch   160  of    554.    Elapsed: 0:02:33.
  Batch   200  of    554.    Elapsed: 0:03:11.
  Batch   240  of    554.    Elapsed: 0:03:49.
  Batch   280  of    554.    Elapsed: 0:04:27.
  Batch   320  of    554.    Elapsed: 0:05:05.
  Batch   360  of    554.    Elapsed: 0:05:43.
  Batch   400  of    554.    Elapsed: 0:06:22.
  Batch   440  of    554.    Elapsed: 0:07:00.
  Batch   480  of    554.    Elapsed: 0:07:38.
  Batch   520  of    554.    Elapsed: 0:08:16.

  Average training loss: 0.57
  Training epcoh took: 0:08:48

======== Epoch 2 / 2 ========
Training...
  Batch    40  of    554.    Elapsed: 0:00:38.
  Batch    80  of    554.    Elapsed: 0:01:16.
  Batch   120  of    554.    Elapsed: 0:01:55.
  Batch   160  of    554.    Elapsed: 0:02:33.
  Batch   200  of    554.    Elapsed: 0:03:11.
  Batch   240  of    554.    Elapsed: 0:03:49.
  Batch   280  of    554.    Elapsed: 0:04:27.
  Batch   320  of    554.    Elapsed: 0:05:05.
  Batch   360  of    554.    Elapsed: 0:05:44.
  Batch   400  of    554.    Elapsed: 0:06:22.
  Batch   440  of    554.    Elapsed: 0:07:00.
  Batch   480  of    554.    Elapsed: 0:07:38.
  Batch   520  of    554.    Elapsed: 0:08:16.

  Average training loss: 0.32
  Training epcoh took: 0:08:48

Training complete!
Finished train hate speech model
Starting evaluation: test data
  Accuracy: 0.88
  F1: 0.88
  Validation took: 0:00:15
Finished evaluation: test data
Finished experiment execution
