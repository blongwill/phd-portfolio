DATASETS: ['/home2/simnayak/ling575_neural_models/src/../datasets/english_processed_nostop.txt']###
Experiment config settings:
config_name: english_2
random_seed: 121
dataset: english_processed_nostop
model_type: bert-base-uncased
optimizer: AdamW
learning_rate: 2e-5
epsilon: 1e-8
num_training_epochs: 2
num_warmup_steps: 0
num_classifier_labels: 4
output_attentions: True
output_hidden_states: True
batch_size: 16
max_tokens_length: 40
###
Starting experiment execution
There are 1 GPU(s) available.
We will use the GPU:Tesla P4
Starting load dataset
First data label: 1
Finished load dataset
Loading BERT tokenizer...
Starting split dataset
Input IDs dimension-1 size: 61053
Input IDs dimension-2 size: 40
Input Labels dimension-1 size: 61053
Input Masks dimension-1 size: 61053
Input Masks dimension-2 size: 40
Train inputs dimension-1 size: 54947
Train inputs dimension-2 size: 40
Train labels dimension-1 size: 54947
Train masks dimension-1 size: 54947
Train masks dimension-2 size: 40
Finished split dataset
Made it here
Starting to Load BertForSequenceClassification
Finished initializing model
Starting train hate speech model

======== Epoch 1 / 2 ========
Training...
  Batch    40  of  3,435.    Elapsed: 0:00:08.
  Batch    80  of  3,435.    Elapsed: 0:00:16.
  Batch   120  of  3,435.    Elapsed: 0:00:24.
  Batch   160  of  3,435.    Elapsed: 0:00:32.
  Batch   200  of  3,435.    Elapsed: 0:00:40.
  Batch   240  of  3,435.    Elapsed: 0:00:48.
  Batch   280  of  3,435.    Elapsed: 0:00:55.
  Batch   320  of  3,435.    Elapsed: 0:01:03.
  Batch   360  of  3,435.    Elapsed: 0:01:11.
  Batch   400  of  3,435.    Elapsed: 0:01:19.
  Batch   440  of  3,435.    Elapsed: 0:01:27.
  Batch   480  of  3,435.    Elapsed: 0:01:34.
  Batch   520  of  3,435.    Elapsed: 0:01:42.
  Batch   560  of  3,435.    Elapsed: 0:01:50.
  Batch   600  of  3,435.    Elapsed: 0:01:58.
  Batch   640  of  3,435.    Elapsed: 0:02:06.
  Batch   680  of  3,435.    Elapsed: 0:02:14.
  Batch   720  of  3,435.    Elapsed: 0:02:22.
  Batch   760  of  3,435.    Elapsed: 0:02:30.
  Batch   800  of  3,435.    Elapsed: 0:02:37.
  Batch   840  of  3,435.    Elapsed: 0:02:45.
  Batch   880  of  3,435.    Elapsed: 0:02:53.
  Batch   920  of  3,435.    Elapsed: 0:03:01.
  Batch   960  of  3,435.    Elapsed: 0:03:09.
  Batch 1,000  of  3,435.    Elapsed: 0:03:17.
  Batch 1,040  of  3,435.    Elapsed: 0:03:25.
  Batch 1,080  of  3,435.    Elapsed: 0:03:33.
  Batch 1,120  of  3,435.    Elapsed: 0:03:41.
  Batch 1,160  of  3,435.    Elapsed: 0:03:49.
  Batch 1,200  of  3,435.    Elapsed: 0:03:56.
  Batch 1,240  of  3,435.    Elapsed: 0:04:04.
  Batch 1,280  of  3,435.    Elapsed: 0:04:12.
  Batch 1,320  of  3,435.    Elapsed: 0:04:20.
  Batch 1,360  of  3,435.    Elapsed: 0:04:28.
  Batch 1,400  of  3,435.    Elapsed: 0:04:36.
  Batch 1,440  of  3,435.    Elapsed: 0:04:44.
  Batch 1,480  of  3,435.    Elapsed: 0:04:52.
  Batch 1,520  of  3,435.    Elapsed: 0:05:00.
  Batch 1,560  of  3,435.    Elapsed: 0:05:08.
  Batch 1,600  of  3,435.    Elapsed: 0:05:16.
  Batch 1,640  of  3,435.    Elapsed: 0:05:23.
  Batch 1,680  of  3,435.    Elapsed: 0:05:31.
  Batch 1,720  of  3,435.    Elapsed: 0:05:39.
  Batch 1,760  of  3,435.    Elapsed: 0:05:47.
  Batch 1,800  of  3,435.    Elapsed: 0:05:55.
  Batch 1,840  of  3,435.    Elapsed: 0:06:03.
  Batch 1,880  of  3,435.    Elapsed: 0:06:11.
  Batch 1,920  of  3,435.    Elapsed: 0:06:19.
  Batch 1,960  of  3,435.    Elapsed: 0:06:26.
  Batch 2,000  of  3,435.    Elapsed: 0:06:34.
  Batch 2,040  of  3,435.    Elapsed: 0:06:42.
  Batch 2,080  of  3,435.    Elapsed: 0:06:50.
  Batch 2,120  of  3,435.    Elapsed: 0:06:58.
  Batch 2,160  of  3,435.    Elapsed: 0:07:05.
  Batch 2,200  of  3,435.    Elapsed: 0:07:13.
  Batch 2,240  of  3,435.    Elapsed: 0:07:21.
  Batch 2,280  of  3,435.    Elapsed: 0:07:29.
  Batch 2,320  of  3,435.    Elapsed: 0:07:37.
  Batch 2,360  of  3,435.    Elapsed: 0:07:45.
  Batch 2,400  of  3,435.    Elapsed: 0:07:53.
  Batch 2,440  of  3,435.    Elapsed: 0:08:01.
  Batch 2,480  of  3,435.    Elapsed: 0:08:09.
  Batch 2,520  of  3,435.    Elapsed: 0:08:17.
  Batch 2,560  of  3,435.    Elapsed: 0:08:25.
  Batch 2,600  of  3,435.    Elapsed: 0:08:32.
  Batch 2,640  of  3,435.    Elapsed: 0:08:40.
  Batch 2,680  of  3,435.    Elapsed: 0:08:48.
  Batch 2,720  of  3,435.    Elapsed: 0:08:56.
  Batch 2,760  of  3,435.    Elapsed: 0:09:04.
  Batch 2,800  of  3,435.    Elapsed: 0:09:12.
  Batch 2,840  of  3,435.    Elapsed: 0:09:20.
  Batch 2,880  of  3,435.    Elapsed: 0:09:28.
  Batch 2,920  of  3,435.    Elapsed: 0:09:36.
  Batch 2,960  of  3,435.    Elapsed: 0:09:44.
  Batch 3,000  of  3,435.    Elapsed: 0:09:52.
  Batch 3,040  of  3,435.    Elapsed: 0:10:00.
  Batch 3,080  of  3,435.    Elapsed: 0:10:08.
  Batch 3,120  of  3,435.    Elapsed: 0:10:16.
  Batch 3,160  of  3,435.    Elapsed: 0:10:23.
  Batch 3,200  of  3,435.    Elapsed: 0:10:31.
  Batch 3,240  of  3,435.    Elapsed: 0:10:39.
  Batch 3,280  of  3,435.    Elapsed: 0:10:47.
  Batch 3,320  of  3,435.    Elapsed: 0:10:55.
  Batch 3,360  of  3,435.    Elapsed: 0:11:03.
  Batch 3,400  of  3,435.    Elapsed: 0:11:11.

  Average training loss: 0.52
  Training epcoh took: 0:11:18

======== Epoch 2 / 2 ========
Training...
  Batch    40  of  3,435.    Elapsed: 0:00:08.
  Batch    80  of  3,435.    Elapsed: 0:00:16.
  Batch   120  of  3,435.    Elapsed: 0:00:24.
  Batch   160  of  3,435.    Elapsed: 0:00:32.
  Batch   200  of  3,435.    Elapsed: 0:00:40.
  Batch   240  of  3,435.    Elapsed: 0:00:48.
  Batch   280  of  3,435.    Elapsed: 0:00:56.
  Batch   320  of  3,435.    Elapsed: 0:01:04.
  Batch   360  of  3,435.    Elapsed: 0:01:12.
  Batch   400  of  3,435.    Elapsed: 0:01:20.
  Batch   440  of  3,435.    Elapsed: 0:01:28.
  Batch   480  of  3,435.    Elapsed: 0:01:35.
  Batch   520  of  3,435.    Elapsed: 0:01:43.
  Batch   560  of  3,435.    Elapsed: 0:01:51.
  Batch   600  of  3,435.    Elapsed: 0:01:59.
  Batch   640  of  3,435.    Elapsed: 0:02:07.
  Batch   680  of  3,435.    Elapsed: 0:02:15.
  Batch   720  of  3,435.    Elapsed: 0:02:23.
  Batch   760  of  3,435.    Elapsed: 0:02:31.
  Batch   800  of  3,435.    Elapsed: 0:02:39.
  Batch   840  of  3,435.    Elapsed: 0:02:47.
  Batch   880  of  3,435.    Elapsed: 0:02:55.
  Batch   920  of  3,435.    Elapsed: 0:03:03.
  Batch   960  of  3,435.    Elapsed: 0:03:11.
  Batch 1,000  of  3,435.    Elapsed: 0:03:19.
  Batch 1,040  of  3,435.    Elapsed: 0:03:27.
  Batch 1,080  of  3,435.    Elapsed: 0:03:34.
  Batch 1,120  of  3,435.    Elapsed: 0:03:42.
  Batch 1,160  of  3,435.    Elapsed: 0:03:50.
  Batch 1,200  of  3,435.    Elapsed: 0:03:58.
  Batch 1,240  of  3,435.    Elapsed: 0:04:06.
  Batch 1,280  of  3,435.    Elapsed: 0:04:14.
  Batch 1,320  of  3,435.    Elapsed: 0:04:22.
  Batch 1,360  of  3,435.    Elapsed: 0:04:30.
  Batch 1,400  of  3,435.    Elapsed: 0:04:38.
  Batch 1,440  of  3,435.    Elapsed: 0:04:46.
  Batch 1,480  of  3,435.    Elapsed: 0:04:54.
  Batch 1,520  of  3,435.    Elapsed: 0:05:02.
  Batch 1,560  of  3,435.    Elapsed: 0:05:10.
  Batch 1,600  of  3,435.    Elapsed: 0:05:18.
  Batch 1,640  of  3,435.    Elapsed: 0:05:26.
  Batch 1,680  of  3,435.    Elapsed: 0:05:33.
  Batch 1,720  of  3,435.    Elapsed: 0:05:41.
  Batch 1,760  of  3,435.    Elapsed: 0:05:49.
  Batch 1,800  of  3,435.    Elapsed: 0:05:57.
  Batch 1,840  of  3,435.    Elapsed: 0:06:05.
  Batch 1,880  of  3,435.    Elapsed: 0:06:13.
  Batch 1,920  of  3,435.    Elapsed: 0:06:21.
  Batch 1,960  of  3,435.    Elapsed: 0:06:29.
  Batch 2,000  of  3,435.    Elapsed: 0:06:37.
  Batch 2,040  of  3,435.    Elapsed: 0:06:45.
  Batch 2,080  of  3,435.    Elapsed: 0:06:53.
  Batch 2,120  of  3,435.    Elapsed: 0:07:01.
  Batch 2,160  of  3,435.    Elapsed: 0:07:09.
  Batch 2,200  of  3,435.    Elapsed: 0:07:16.
  Batch 2,240  of  3,435.    Elapsed: 0:07:24.
  Batch 2,280  of  3,435.    Elapsed: 0:07:32.
  Batch 2,320  of  3,435.    Elapsed: 0:07:40.
  Batch 2,360  of  3,435.    Elapsed: 0:07:48.
  Batch 2,400  of  3,435.    Elapsed: 0:07:56.
  Batch 2,440  of  3,435.    Elapsed: 0:08:04.
  Batch 2,480  of  3,435.    Elapsed: 0:08:12.
  Batch 2,520  of  3,435.    Elapsed: 0:08:20.
  Batch 2,560  of  3,435.    Elapsed: 0:08:28.
  Batch 2,600  of  3,435.    Elapsed: 0:08:36.
  Batch 2,640  of  3,435.    Elapsed: 0:08:44.
  Batch 2,680  of  3,435.    Elapsed: 0:08:52.
  Batch 2,720  of  3,435.    Elapsed: 0:09:00.
  Batch 2,760  of  3,435.    Elapsed: 0:09:08.
  Batch 2,800  of  3,435.    Elapsed: 0:09:15.
  Batch 2,840  of  3,435.    Elapsed: 0:09:23.
  Batch 2,880  of  3,435.    Elapsed: 0:09:31.
  Batch 2,920  of  3,435.    Elapsed: 0:09:39.
  Batch 2,960  of  3,435.    Elapsed: 0:09:47.
  Batch 3,000  of  3,435.    Elapsed: 0:09:55.
  Batch 3,040  of  3,435.    Elapsed: 0:10:03.
  Batch 3,080  of  3,435.    Elapsed: 0:10:11.
  Batch 3,120  of  3,435.    Elapsed: 0:10:19.
  Batch 3,160  of  3,435.    Elapsed: 0:10:27.
  Batch 3,200  of  3,435.    Elapsed: 0:10:35.
  Batch 3,240  of  3,435.    Elapsed: 0:10:43.
  Batch 3,280  of  3,435.    Elapsed: 0:10:51.
  Batch 3,320  of  3,435.    Elapsed: 0:10:59.
  Batch 3,360  of  3,435.    Elapsed: 0:11:06.
  Batch 3,400  of  3,435.    Elapsed: 0:11:14.

  Average training loss: 0.41
  Training epcoh took: 0:11:21

Training complete!
Finished train hate speech model
Starting evaluation: test data
  Accuracy: 0.82
  F1: 0.81
  Validation took: 0:00:16
Finished evaluation: test data
Finished experiment execution
Starting visualization of trained model
Loading BERT tokenizer...
No GPU available, using the CPU instead.
Finished visualization of trained model given input RT USER Horse face hoe stop playing before I show the world yo lil ugly ass

HTML file saved to viz/english_2/english_abusive/RT USER Ho
No GPU available, using the CPU instead.
Finished visualization of trained model given input I repeat... What the bloody hell is happening! 🙈👀  URL

HTML file saved to viz/english_2/english_abusive/I repeat..
No GPU available, using the CPU instead.
Finished visualization of trained model given input WBA.... Why Bother Attacking.... retarded ass team what's the point of playing defensive for 90 mins??

HTML file saved to viz/english_2/english_abusive/WBA.... Wh
No GPU available, using the CPU instead.
Finished visualization of trained model given input STRANGLE THIS EVIL FUCK TO DEATH!	

HTML file saved to viz/english_2/english_abusive/STRANGLE T
No GPU available, using the CPU instead.
Finished visualization of trained model given input USER USER your an idiot TROLL and the furthest thing from what you think you are 007 is your frigging IQ

HTML file saved to viz/english_2/english_abusive/USER USER 
No GPU available, using the CPU instead.
Finished visualization of trained model given input It's always the filthy bitch that comes in the picture.. 🤦🏽‍♂️
HTML file saved to viz/english_2/english_abusive/It's alway
Starting visualization of trained model
Loading BERT tokenizer...
No GPU available, using the CPU instead.
Finished visualization of trained model given input If You Think It Isn't , Go To Hell , I Hate You And I Wanna Stab You To Death

HTML file saved to viz/english_2/english_hate/If You Thi
No GPU available, using the CPU instead.
Finished visualization of trained model given input RT USER Bloody Islamic Bastards URL

HTML file saved to viz/english_2/english_hate/RT USER Bl
No GPU available, using the CPU instead.
Finished visualization of trained model given input RT USER i'm tired of u feminist bitches bc this is just disgusting URL

HTML file saved to viz/english_2/english_hate/RT USER i'
No GPU available, using the CPU instead.
Finished visualization of trained model given input USER u r a slim bag &amp; puppet for USER so why dont u go ask him 4 permission to speak u idiot

HTML file saved to viz/english_2/english_hate/USER u r a
No GPU available, using the CPU instead.
Finished visualization of trained model given input RT USER USER USER : Call me  anti-Muslim, but, I like womens's feet!  Muzzies be crazy intolerant!

HTML file saved to viz/english_2/english_hate/RT USER US
No GPU available, using the CPU instead.
Finished visualization of trained model given input USER Perhaps an IQ test should be a requirement for members of Congress. This idiot and Sheila Jackson Lee would flunk
HTML file saved to viz/english_2/english_hate/USER Perha
Starting visualization of trained model
Loading BERT tokenizer...
No GPU available, using the CPU instead.
Finished visualization of trained model given input too bad i ain't packing like that banana 😞💔 URL

HTML file saved to viz/english_2/english_normal/too bad i 
No GPU available, using the CPU instead.
Finished visualization of trained model given input Carlos Correa had gyalchester as his walkup music and it was so bad ass 😂

HTML file saved to viz/english_2/english_normal/Carlos Cor
No GPU available, using the CPU instead.
Finished visualization of trained model given input RT USER Papaya has to be the worst fruit ever

HTML file saved to viz/english_2/english_normal/RT USER Pa
No GPU available, using the CPU instead.
Finished visualization of trained model given input RT USER lesson of the day: fight salty ass hate with poems 🙂 URL

HTML file saved to viz/english_2/english_normal/RT USER le
No GPU available, using the CPU instead.
Finished visualization of trained model given input USER ugh, crippling self doubt is THE WORST.
HTML file saved to viz/english_2/english_normal/USER ugh, 
